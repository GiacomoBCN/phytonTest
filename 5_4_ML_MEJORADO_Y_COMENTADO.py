# ============================================
# GRADIENT BOOSTING REGRESSOR - C√ìDIGO MEJORADO Y COMENTADO
# ============================================
# Este c√≥digo busca los mejores hiperpar√°metros para GradientBoostingRegressor
# y eval√∫a los 5 mejores modelos en un segundo round

import numpy as np
import pandas as pd
from scipy.stats import randint, uniform, loguniform
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error

# ============================================
# PASO 1: CONFIGURACI√ìN DEL MODELO BASE
# ============================================
# Creamos el modelo GradientBoostingRegressor con random_state fijo
# para garantizar reproducibilidad de resultados
gbr = GradientBoostingRegressor(random_state=42)

# ============================================
# PASO 2: DEFINICI√ìN DEL ESPACIO DE HIPERPAR√ÅMETROS
# ============================================
# Definimos las distribuciones de valores a probar para cada hiperpar√°metro

param_dist = {
    # ---- FUNCI√ìN DE P√âRDIDA ----
    # - squared_error: MSE est√°ndar (mejor para datos sin outliers extremos)
    # - huber: Robusta a outliers (combinaci√≥n de MSE y MAE)
    # - absolute_error: MAE (muy robusta pero m√°s lenta)
    "loss": ["squared_error", "huber", "absolute_error"],
    
    # ---- LEARNING RATE Y N√öMERO DE √ÅRBOLES ----
    # Learning rate bajo + m√°s √°rboles = mejor generalizaci√≥n (pero m√°s lento)
    # loguniform: explora valores logar√≠tmicamente distribuidos
    "learning_rate": loguniform(1e-3, 3e-1),     # Rango: 0.001 - 0.3
    "n_estimators": randint(150, 1201),          # Rango: 150 - 1200 √°rboles
    
    # ---- STOCHASTIC GRADIENT BOOSTING ----
    # subsample < 1.0 usa una fracci√≥n aleatoria de datos en cada √°rbol
    # Ayuda a prevenir overfitting y acelera el entrenamiento
    "subsample": uniform(0.6, 0.4),              # Rango: 0.6 - 1.0
    
    # ---- ESTRUCTURA DEL √ÅRBOL ----
    # √Årboles poco profundos para datos con tendencia lineal
    "max_depth": randint(2, 5),                  # Rango: 2 - 4
    
    # M√≠nimo de muestras para dividir un nodo (como fracci√≥n del total)
    "min_samples_split": uniform(0.02, 0.18),    # Rango: 0.02 - 0.20 (2%-20%)
    
    # M√≠nimo de muestras en cada hoja (como fracci√≥n del total)
    "min_samples_leaf": uniform(0.01, 0.09),     # Rango: 0.01 - 0.10 (1%-10%)
    
    # N√∫mero de features a considerar en cada split
    # None = todas, "sqrt" = ra√≠z cuadrada del total
    "max_features": [None, 1.0, 0.8, "sqrt"],
    
    # ---- CRITERIO DE SPLIT ----
    # friedman_mse: optimizado para gradient boosting (recomendado)
    # squared_error: MSE est√°ndar
    "criterion": ["friedman_mse", "squared_error"],
    
    # ---- REGULARIZACI√ìN ----
    # Reducci√≥n m√≠nima de impureza requerida para hacer un split
    "min_impurity_decrease": uniform(0.0, 0.002),
    
    # Cost-complexity pruning alpha (mayor = m√°s poda)
    "ccp_alpha": uniform(0.0, 0.01),
    
    # ---- PAR√ÅMETRO ESPEC√çFICO PARA HUBER ----
    # Solo relevante si loss='huber' o 'quantile'
    # Alpha determina el quantile (valores altos = m√°s robusto)
    "alpha": uniform(0.85, 0.14),                # Rango: 0.85 - 0.99
    
    # ---- EARLY STOPPING (PARADA TEMPRANA) ----
    # Fracci√≥n de datos usada para validaci√≥n interna
    "validation_fraction": uniform(0.1, 0.1),    # Rango: 0.10 - 0.20
    
    # N√∫mero de iteraciones sin mejora antes de parar
    "n_iter_no_change": randint(5, 16),          # Rango: 5 - 15
    
    # Tolerancia m√≠nima de mejora requerida
    "tol": loguniform(1e-5, 1e-3),               # Rango: 0.00001 - 0.001
}

# ============================================
# PASO 3: DEFINICI√ìN DE M√âTRICAS DE EVALUACI√ìN
# ============================================
# Usamos scoring negativos porque sklearn maximiza los scores
# (valores menos negativos = mejor)
scoring = {
    "RMSE": "neg_root_mean_squared_error",  # Penaliza errores grandes
    "MAE": "neg_mean_absolute_error",       # M√°s robusto a outliers
}

# ============================================
# PASO 4: CONFIGURACI√ìN DE RANDOMIZEDSEARCHCV
# ============================================
# RandomizedSearchCV prueba combinaciones aleatorias de hiperpar√°metros
# Es m√°s eficiente que GridSearchCV cuando hay muchos par√°metros

gbr_rscv = RandomizedSearchCV(
    gbr,                          # Modelo base
    param_distributions=param_dist,  # Espacio de b√∫squeda
    n_iter=80,                    # ‚úÖ REDUCIDO de 150 a 80 (m√°s r√°pido, igualmente efectivo)
    cv=kf,                        # KFold cross-validation (debe estar definido previamente)
    scoring=scoring,              # M√©tricas a calcular
    refit="RMSE",                 # Reentrena con el mejor modelo seg√∫n RMSE
    n_jobs=-1,                    # Usa todos los cores del CPU
    verbose=1,                    # Muestra progreso
    random_state=42,              # Reproducibilidad
    return_train_score=True,      # Calcula scores en training tambi√©n
)

# ============================================
# PASO 5: ENTRENAMIENTO (B√öSQUEDA DE HIPERPAR√ÅMETROS)
# ============================================
print("üöÄ Iniciando b√∫squeda de hiperpar√°metros...")
print(f"   - Probando {gbr_rscv.n_iter} combinaciones")
print(f"   - Con {kf.n_splits} folds de cross-validation")
print(f"   - Total de entrenamientos: {gbr_rscv.n_iter * kf.n_splits}")
print(f"   - Tiempo estimado: 2-3 minutos\n")

gbr_rscv.fit(X_train, y_train)

print("‚úÖ B√∫squeda completada!\n")

# ============================================
# PASO 6: MOSTRAR MEJORES RESULTADOS
# ============================================

# --- Tabla de mejores hiperpar√°metros ---
best_params = gbr_rscv.best_params_
best_params_table = pd.DataFrame(
    list(best_params.items()), 
    columns=['Hyperparameter', 'Best Value']
)

# --- M√©tricas del mejor modelo ---
train_rmse = -gbr_rscv.cv_results_['mean_train_RMSE'][gbr_rscv.best_index_]
val_rmse   = -gbr_rscv.cv_results_['mean_test_RMSE'][gbr_rscv.best_index_]
train_mae  = -gbr_rscv.cv_results_['mean_train_MAE'][gbr_rscv.best_index_]
val_mae    = -gbr_rscv.cv_results_['mean_test_MAE'][gbr_rscv.best_index_]

metrics_table = pd.DataFrame({
    'Metric': ['RMSE', 'MAE'],
    'Train': [round(train_rmse, 2), round(train_mae, 2)],
    'Validation': [round(val_rmse, 2), round(val_mae, 2)],
})
metrics_table['Difference'] = (metrics_table['Validation'] - metrics_table['Train']).round(2)
metrics_table['% Diff'] = ((metrics_table['Difference'] / metrics_table['Train']) * 100).round(2)

# --- Mostrar resultados ---
print("\n" + "="*60)
print(" MEJORES HIPERPAR√ÅMETROS ENCONTRADOS")
print("="*60 + "\n")
print(best_params_table.to_string(index=False))

print("\n" + "="*60)
print(" RENDIMIENTO DEL MEJOR MODELO")
print("="*60 + "\n")
print(metrics_table.to_string(index=False))
print()

# ============================================
# PASO 7: ROUND 2 - EVALUACI√ìN DE TOP 5 MODELOS
# ============================================
# Tomamos los 5 mejores modelos por MAE y los evaluamos en el test set
# Esto nos da una idea m√°s clara del rendimiento real

print("\n" + "="*60)
print(" ROUND 2: EVALUACI√ìN DE TOP 5 MODELOS")
print("="*60 + "\n")
print("Entrenando los 5 mejores modelos encontrados...")
print("(Esto puede tardar 1-2 minutos)\n")

# 1) Obtener los 5 mejores √≠ndices seg√∫n MAE
cv_mae_neg = gbr_rscv.cv_results_['mean_test_MAE']
cv_rmse_neg = gbr_rscv.cv_results_.get('mean_test_RMSE', None)
cv_mae = -cv_mae_neg  # Convertir a positivo
cv_rmse = -cv_rmse_neg if cv_rmse_neg is not None else None

best_indices = np.argsort(cv_mae)[:5]  # Los 5 MAE m√°s peque√±os

# 2) Entrenar cada modelo y evaluar en train/test
round2_rows = []
for rank, i in enumerate(best_indices, start=1):
    params = gbr_rscv.cv_results_['params'][i]
    
    # Crear y entrenar modelo con estos par√°metros
    model = GradientBoostingRegressor(random_state=42, **params)
    model.fit(X_train, y_train)
    
    # Predecir en train y test
    y_pred_tr = model.predict(X_train)
    y_pred_te = model.predict(X_test)
    
    # Calcular m√©tricas
    mae_tr = mean_absolute_error(y_train, y_pred_tr)
    mae_te = mean_absolute_error(y_test, y_pred_te)
    rmse_tr = np.sqrt(mean_squared_error(y_train, y_pred_tr))
    rmse_te = np.sqrt(mean_squared_error(y_test, y_pred_te))
    
    # Guardar resultados
    row = {
        "Rank": rank,
        "CV MAE": round(float(cv_mae[i]), 2),
        "CV RMSE": round(float(cv_rmse[i]), 2) if cv_rmse is not None else None,
        "Train MAE": round(mae_tr, 2),
        "Test MAE": round(mae_te, 2),
        "Train RMSE": round(rmse_tr, 2),
        "Test RMSE": round(rmse_te, 2),
        "Overfitting": "‚ö†Ô∏è S√≠" if (mae_te - mae_tr) / mae_tr > 0.3 else "‚úÖ No",
        "Params": params
    }
    round2_rows.append(row)

# 3) Crear tabla ordenada por Test MAE (mejor = menor)
round2_df = pd.DataFrame(round2_rows)
round2_df = round2_df.sort_values(by="Test MAE", ascending=True).reset_index(drop=True)

# Mostrar resultados (sin la columna Params para que sea m√°s legible)
display_df = round2_df.drop('Params', axis=1)
print("üîÅ Top 5 Modelos (ordenados por Test MAE):\n")
print(display_df.to_string(index=False))

# ============================================
# PASO 8: SELECCIONAR Y GUARDAR EL MEJOR MODELO
# ============================================
best_round2_params = round2_df.iloc[0]["Params"]
best_round2_model = GradientBoostingRegressor(random_state=42, **best_round2_params)
best_round2_model.fit(X_train, y_train)

print(f"\n‚úÖ Mejor modelo del Round 2:")
print(f"   - Test MAE: {round2_df.iloc[0]['Test MAE']}")
print(f"   - Test RMSE: {round2_df.iloc[0]['Test RMSE']}")
print(f"   - Overfitting: {round2_df.iloc[0]['Overfitting']}")

# ============================================
# RESUMEN Y RECOMENDACIONES
# ============================================
print("\n" + "="*60)
print(" AN√ÅLISIS Y RECOMENDACIONES")
print("="*60 + "\n")

# Calcular diferencia promedio entre train y test
avg_train_mae = round2_df['Train MAE'].mean()
avg_test_mae = round2_df['Test MAE'].mean()
gap_pct = ((avg_test_mae - avg_train_mae) / avg_train_mae) * 100

print(f"üìä Brecha promedio Train-Test: {gap_pct:.1f}%")

if gap_pct < 20:
    print("   ‚úÖ Excelente generalizaci√≥n")
elif gap_pct < 40:
    print("   ‚ö†Ô∏è Generalizaci√≥n aceptable, hay algo de overfitting")
else:
    print("   ‚ùå Overfitting significativo - considera:")
    print("      ‚Ä¢ Aumentar min_samples_leaf")
    print("      ‚Ä¢ Reducir max_depth")
    print("      ‚Ä¢ Aumentar ccp_alpha (regularizaci√≥n)")

print("\nüí° Pr√≥ximos pasos:")
print("   1. Usar 'best_round2_model' para predecir en datos nuevos")
print("   2. Analizar feature importance del modelo")
print("   3. Visualizar errores para entender d√≥nde falla")
print("   4. Si es necesario, hacer un grid search refinado alrededor")
print("      de los mejores hiperpar√°metros encontrados")

print("\n" + "="*60)

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ccf320",
   "metadata": {},
   "source": [
    "ðŸ“‹ TABELLA DEFINITIVA - DATA PREPARATION WORKFLOW\n",
    "Legenda Simboli:\n",
    "\n",
    "âœ… = Step COMUNE a tutti i file (essenziale)\n",
    "ðŸ”µ = Step presente in House Pricing (regressione)\n",
    "ðŸŸ¢ = Step presente in Bank (classificazione)\n",
    "âšª = Step OPZIONALE (dipende dal dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2145240",
   "metadata": {},
   "source": [
    "| #  | **Titolo Sezione**  | **Sottosezione / Operazione**     | ðŸ  House | ðŸ¦ Bank | **Note / Quando usarlo**               |\n",
    "| -- | ------------------- | --------------------------------- | :------: | :-----: | -------------------------------------- |\n",
    "| 1  | SETUP               | Imports                           |     âœ…    |    âœ…    | pandas, numpy, matplotlib, sklearn     |\n",
    "| 2  | SETUP               | Load dataset                      |     âœ…    |    âœ…    | `pd.read_csv()` + `.head()` + `.shape` |\n",
    "| 3  | Select Data         | Decidere quali dataset usare      |     âœ…    |    âœ…    | Di solito non câ€™Ã¨ nulla da scegliere   |\n",
    "| 4  | Clean Data          | Remove unnecessary features       |     âœ…    |    âšª    | Drop Id, colonne inutili               |\n",
    "| 5  | Clean Data          | Sostituire valori erronei         |    ðŸ”µ    |    ðŸŸ¢   | Es: `\"?\" â†’ \"unknown\"`                  |\n",
    "| 6  | Clean Data          | Gestire valori null / errati      |     âœ…    |    âœ…    | `fillna({col: val})`                   |\n",
    "| 7  | Clean Data          | Imputazione avanzata NaN          |     âšª    |    ðŸŸ¢   | Es: imputazione probabilistica         |\n",
    "| 8  | Clean Data          | Duplicated rows                   |     âœ…    |    âœ…    | `.duplicated().sum()`                  |\n",
    "| 9  | Clean Data          | Gestione outliers                 |     âœ…    |    âœ…    | Spesso: non rimuovere negli esercizi   |\n",
    "| 10 | Construct Data      | Feature binarie da NaN            |    ðŸ”µ    |    ðŸŸ¢   | Es: `HasGarage`, `contacted_before`    |\n",
    "| 11 | Construct Data      | Feature aggregate                 |    ðŸ”µ    |    âšª    | Es: `TotalPorchSF`, `BuiltArea`        |\n",
    "| 12 | Construct Data      | Ratios / percentuali              |    ðŸ”µ    |    âšª    | Es: `BuiltAreaPerc`                    |\n",
    "| 13 | Construct Data      | Boolean da condizioni             |    ðŸ”µ    |    ðŸŸ¢   | Es: `WasRemod`                         |\n",
    "| 14 | Construct Data      | Binning â†’ categorie               |     âšª    |    ðŸŸ¢   | Es: `age_group`, `balance_category`    |\n",
    "| 15 | Construct Data      | Feature composite                 |     âšª    |    ðŸŸ¢   | Es: `economic_profile`                 |\n",
    "| 16 | Construct Data      | Feature temporali / stagionali    |     âšª    |    ðŸŸ¢   | Es: `season` da `month`                |\n",
    "| 17 | Integrate Data      | Dati esterni                      |     âšª    |    âšª    | Quasi mai necessario                   |\n",
    "| 18 | Feature Engineering | Encoding - Header                 |     âœ…    |    âœ…    | Sezione principale encoding            |\n",
    "| 19 | Feature Engineering | Identificare colonne object       |     âœ…    |    âœ…    | `select_dtypes('object')`              |\n",
    "| 20 | Feature Engineering | Mini-study per ordinale           |    ðŸ”µ    |    âšª    | Analisi prezzi per decidere ordine     |\n",
    "| 21 | Feature Engineering | Ordinal encoding manuale          |    ðŸ”µ    |    ðŸŸ¢   | Dizionari `{cat: num}`                 |\n",
    "| 22 | Feature Engineering | One-Hot Encoding                  |    ðŸ”µ    |    ðŸŸ¢   | `pd.get_dummies(drop_first=True)`      |\n",
    "| 23 | Feature Engineering | Binary encoding (yes/no)          |    ðŸ”µ    |    ðŸŸ¢   | Es: `default`, `loan`                  |\n",
    "| 24 | Feature Engineering | Target Encoding                   |     âŒ    |    ðŸŸ¢   | Target binario â†’ 0/1                   |\n",
    "| 25 | Feature Engineering | Convertire bool â†’ int             |     âšª    |    ðŸŸ¢   | `.astype(int)`                         |\n",
    "| 26 | Feature Engineering | Convertire category â†’ ordinal int |     âšª    |    ðŸŸ¢   | Per feature ordinali                   |\n",
    "| 27 | Feature Engineering | Verifica finale tipi dati         |     âšª    |    ðŸŸ¢   | Tutto numerico                         |\n",
    "| 28 | Correlazioni        | Analisi correlazioni              |     âšª    |    ðŸŸ¢   | Heatmap, top correlazioni              |\n",
    "| 29 | Correlazioni        | High correlation removal          |    ðŸ”µ    |    âšª    | Drop feature corr > 0.95               |\n",
    "| 30 |Save Dataset        | Save new  dataset                  |     âœ…    |    âœ…    | `df.to_csv()` finale                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a47aa7",
   "metadata": {},
   "source": [
    "ðŸŽ¯ PATTERN COMUNI IDENTIFICATI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb914ce2",
   "metadata": {},
   "source": [
    "A. Gestione Missing Values\n",
    "\n",
    "# Pattern standard\n",
    "na_subs = {\n",
    "    'Electrical': 'SBrkr',          # categorica â†’ moda\n",
    "    'GarageYrBlt': 0,               # numerica â†’ 0 o media\n",
    "    'GarageType': 'NoGarage'        # categorica â†’ valore specifico\n",
    "}\n",
    "df.fillna(na_subs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ef97a",
   "metadata": {},
   "source": [
    "ðŸ“Œ DIFFERENZE CHIAVE: Regressione vs Classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5d03f",
   "metadata": {},
   "source": [
    "| **Aspetto**         | **Regressione (House)**                | **Classificazione (Bank)**          |\n",
    "| ------------------- | -------------------------------------- | ----------------------------------- |\n",
    "| Target encoding     | âŒ Resta numerica                       | âœ… Convertito in 1/0                 |\n",
    "| Feature engineering | Focus su ratios, superfici, aggregati  | Focus su binning, categorie, gruppi |\n",
    "| Correlazioni        | âœ… Si rimuovono feature molto correlate | âšª Analizzate ma spesso non rimosse  |\n",
    "| Encoding dominante  | Ordinale basato su prezzo/valori       | One-Hot + Ordinale misto            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b59c5",
   "metadata": {},
   "source": [
    " # | STEP | DESCRIZIONE | PRESENTE IN |\n",
    "|---|------|-------------|-------------|\n",
    "| 1 | **Imports** | Importare librerie necessarie (pandas, numpy, matplotlib, seaborn, sklearn) | File 1, 2, 3, 4 |\n",
    "| 2 | **Load Dataset** | Caricare il CSV con pd.read_csv() | File 1, 2, 3, 4 |\n",
    "| 3 | **Select Data** | Decidere quali dataset/features usare (opzionale) | File 3, 4 |\n",
    "| 4 | **Remove Unnecessary Features** | Eliminare colonne inutili/ridondanti (ID, split, ecc.) | File 1, 4 |\n",
    "| 5 | **Clean Data - Sostituire Valori Errati** | Sostituire valori come '?' con 'unknown' o valori corretti | File 4 |\n",
    "| 6 | **Handle Missing Values - Identificazione** | Identificare NaN/missing values per colonna | File 1, 2, 3, 4 |\n",
    "| 7 | **Handle Missing Values - Imputazione** | Imputare missing con media/mediana/moda/strategia custom | File 1, 2, 3, 4 |\n",
    "| 8 | **Handle Missing Values - Rimozione** | Rimuovere righe/colonne con troppi missing | File 1, 3 |\n",
    "| 9 | **Outlier Detection** | Identificare outlier con IQR, z-score, o visualizzazioni | File 1 |\n",
    "| 10 | **Outlier Treatment** | Gestire outlier (cap, remove, transform) | File 1 |\n",
    "| 11 | **Encoding - Label Encoding** | Encoding ordinale per variabili categoriche ordinate | File 2, 3, 4 |\n",
    "| 12 | **Encoding - One-Hot Encoding** | Creare dummy variables per categoriche nominali | File 1, 2, 3, 4 |\n",
    "| 13 | **Encoding - Target Encoding** | Encoding basato sul target (media target per categoria) | File 1 |\n",
    "| 14 | **Encoding - Frequency Encoding** | Encoding basato sulla frequenza della categoria | File 1 |\n",
    "| 15 | **Feature Engineering - Binning** | Creare categorie/gruppi da variabili continue (age_group, ecc.) | File 1, 4 |\n",
    "| 16 | **Feature Engineering - Interazioni** | Creare feature combinando altre (ratio, prodotto, ecc.) | File 1 |\n",
    "| 17 | **Feature Engineering - Date Features** | Estrarre componenti da date (giorno, mese, stagione) | File 1, 4 |\n",
    "| 18 | **Feature Engineering - Cyclical Features** | Trasformare variabili cicliche con sin/cos (mese, giorno) | File 1 |\n",
    "| 19 | **Feature Engineering - Boolean Features** | Creare flag binari (has_X, is_Y) | File 2, 4 |\n",
    "| 20 | **Feature Engineering - Aggregazioni** | Creare feature aggregate (count, sum, mean per gruppo) | File 1 |\n",
    "| 21 | **Feature Scaling/Normalization** | Standardizzare o normalizzare features numeriche | File 1 |\n",
    "| 22 | **Check Correlations** | Calcolare matrice di correlazione tra features | File 1, 4 |\n",
    "| 23 | **Remove Highly Correlated Features** | Rimuovere feature con correlazione > soglia (0.8-0.9) | File 1, 3 |\n",
    "| 24 | **Train-Test Split** | Separare train e test set (se non giÃ  fatto) | File 1 |\n",
    "| 25 | **Target Encoding (sul train)** | Applicare target encoding usando SOLO train set | File 1 |\n",
    "| 26 | **Convert Target to Numeric** | Convertire target da categorico a numerico (yes/no â†’ 1/0) | File 4 |\n",
    "| 27 | **Final Data Validation** | Verificare dtypes, shape, missing values finali | File 1, 2, 4 |\n",
    "| 28 | **Save Prepared Dataset** | Salvare il dataframe processato in CSV | File 1, 2, 3, 4 |\n",
    "\n",
    "---\n",
    "\n",
    "## NOTE IMPORTANTI:\n",
    "\n",
    "### ORDINE CRITICO:\n",
    "1. **Missing Values** â†’ va fatto PRIMA di encoding e feature engineering\n",
    "2. **Outlier** â†’ dopo missing, prima di scaling\n",
    "3. **Train/Test Split** â†’ PRIMA di scaling e target encoding (per evitare data leakage)\n",
    "4. **Encoding ordinale** â†’ quando la variabile ha ordine naturale (low < medium < high)\n",
    "5. **One-Hot** â†’ quando la variabile NON ha ordine (colori, categorie)\n",
    "6. **Target Encoding** â†’ SOLO dopo split, usando train set\n",
    "7. **Scaling** â†’ ultimo step prima del salvataggio\n",
    "8. **Correlations** â†’ controllare DOPO feature engineering\n",
    "\n",
    "### DECISIONI CONTEXT-DEPENDENT:\n",
    "- **Binning**: dipende dal dataset e dalla variabile\n",
    "- **Cyclical encoding**: solo per variabili cicliche (mese, ora, giorno settimana)\n",
    "- **Outlier removal**: dipende dal problema e dal modello\n",
    "- **Feature selection**: dipende da correlazioni e importanza\n",
    "\n",
    "### DATA LEAKAGE - ATTENZIONE:\n",
    "- Target encoding: calcolare SOLO su train, applicare a test\n",
    "- Scaling: fit SOLO su train, transform su test\n",
    "- Imputazione: strategia puÃ² essere calcolata su train\n",
    "\n",
    "---\n",
    "\n",
    "## STEP MINIMI PER UN TEMPLATE GENERICO:\n",
    "1. Load dataset\n",
    "2. Identify and handle missing values\n",
    "3. Encode categorical variables\n",
    "4. Feature engineering (opzionale ma consigliato)\n",
    "5. Check correlations\n",
    "6. Save prepared dataset\n",
    "\n",
    "**Per esame**: prepara funzioni riutilizzabili per ogni step!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38111f2f",
   "metadata": {},
   "source": [
    "| Nome dello step                                         | Breve descrizione dello step                                                                                                                                                                                                |\n",
    "| ------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Importazione librerie                                   | Importare tutte le librerie necessarie (pandas, numpy, matplotlib, seaborn, scikit-learn, ecc.) per manipolazione dati, modellazione, metriche, scaling, pipeline e validazione incrociata.                                 |\n",
    "| Caricamento dataset pulito                              | Caricare dal file CSV il dataset già preparato (output di `data_preparation.ipynb`), verificando percorso e nome del file.                                                                                                  |\n",
    "| Controlli veloci sul dataset                            | Fare un controllo rapido: `head()`, `info()`, `describe()`, numero di righe/colonne, tipi delle colonne, presenza di eventuali NaN residui. Serve solo per confermare che il dataset è pronto alla modellazione.            |\n",
    "| Gestione ultimi missing values                          | Se presenti ancora valori mancanti o anomali, gestirli (es. drop di poche righe, imputazione semplice con media/mediana/moda) in modo esplicito e documentato.                                                              |\n",
    "| Encoding variabili categoriche (se necessario)          | Se nel dataset sono rimaste colonne categoriche non codificate, applicare un encoding semplice (One-Hot, Ordinal o LabelEncoder) in questa fase, così da avere solo variabili numeriche per il modello.                     |\n",
    "| Feature engineering finale (opzionale)                  | Creare eventuali ultime feature derivate semplici (aggregazioni, rapporti, trasformazioni log ecc.) assicurandosi di non introdurre leakage (niente info dal target o dal test).                                            |\n",
    "| Definizione feature (X) e target (y)                    | Separare chiaramente le colonne delle feature `X` dalla colonna di output `y` (il target della regressione), escludendo eventuali ID o variabili non utili.                                                                 |\n",
    "| Train/Test split                                        | Dividere il dataset in training e test set (tipicamente 70/30 o 80/20) usando `train_test_split` con `random_state` fissato per riproducibilità.                                                                            |\n",
    "| Definizione schema di cross-validation                  | Impostare uno schema di validazione incrociata (es. `KFold` o `cross_validate`) per valutare i modelli in modo robusto sul training set, scegliendo il numero di fold e se mischiare i dati (`shuffle`).                    |\n",
    "| Definizione funzione generica per le metriche           | Creare una funzione riutilizzabile che, dati `y_true` e `y_pred`, calcoli e stampi le metriche di regressione principali: MSE, RMSE, MAE, R² (ed eventualmente altre). Può anche restituire un dizionario di risultati.     |\n",
    "| Definizione scaler e pipeline                           | Definire uno o più scaler (`StandardScaler`, `MinMaxScaler`, ecc.) e costruire una `Pipeline` che applichi prima lo scaling e poi il modello di regressione, per evitare leakage e semplificare il codice.                  |\n",
    "| Modello baseline (DummyRegressor)                       | Addestrare un modello di baseline molto semplice (es. `DummyRegressor` con strategia “mean” o “median”) e valutarlo con cross-validation, per avere un riferimento minimo di performance.                                   |\n",
    "| Regressione lineare con scaling                         | Definire e addestrare un modello di `LinearRegression` inserito in pipeline con lo scaler; valutarlo tramite cross-validation usando sempre le stesse metriche, e confrontarlo con la baseline.                             |\n",
    "| k-Nearest Neighbors Regressor                           | Definire un modello `KNeighborsRegressor` (con `n_neighbors` e `weights` scelti in modo ragionevole) dentro una pipeline con scaler; valutare via cross-validation e confrontare con baseline e regressione lineare.        |\n",
    "| Confronto con/ senza scaling (opzionale)                | Eseguire, per almeno un modello (es. Linear Regression o kNN), un confronto della performance con e senza scaling delle feature, per mostrare l’impatto della normalizzazione.                                              |\n",
    "| Modelli tree-based (opzionale)                          | Addestrare e valutare modelli ad albero per regressione (es. `DecisionTreeRegressor`, `RandomForestRegressor`, `GradientBoostingRegressor`) usando cross-validation, per avere alternative non lineari.                     |\n",
    "| Hyperparameter tuning (opzionale)                       | Eseguire ricerca degli iperparametri con `RandomizedSearchCV` e/o `GridSearchCV` per uno o più modelli (kNN, alberi, GBDT), definendo esplicitamente gli spazi di ricerca e usando le metriche di regressione come scoring. |\n",
    "| Selezione del modello migliore                          | Confrontare i risultati medi di cross-validation (RMSE, MAE, R²) tra baseline e modelli provati, scegliere il modello “migliore” in base alle metriche e alla complessità.                                                  |\n",
    "| Valutazione finale sul test set                         | Rieseguire il fit del modello scelto su tutto il training set e poi calcolare le metriche di regressione sul test set tenuto da parte, usando la funzione generica delle metriche.                                          |\n",
    "| Analisi errori e visualizzazioni                        | Costruire grafici per interpretare le performance: scatter `y_test` vs `y_pred`, distribuzione dei residui, eventualmente heatmap di correlazioni o importanza delle feature per modelli ad albero.                         |\n",
    "| Salvataggio del modello                                 | Salvare il modello finale (e/o la pipeline completa) su disco con `joblib.dump` (o `pickle`) per riutilizzarlo in futuro.                                                                                                   |\n",
    "| Ricarica modello e predizione su nuovi dati (opzionale) | Mostrare un breve esempio di `joblib.load` del modello salvato e di predizione su uno o pochi esempi, per completare il ciclo di utilizzo del modello.                                                                      |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

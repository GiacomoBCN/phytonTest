{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25097036",
   "metadata": {},
   "source": [
    "# Real example of ML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d697c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cfb2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SEZIONE: Importazione Librerie\n",
    "# ============================================\n",
    "# In questa sezione importiamo tutte le librerie necessarie per il progetto di Machine Learning\n",
    "\n",
    "# --- Librerie Base per Data Science ---\n",
    "import numpy as np          # Libreria per calcoli numerici e operazioni su array\n",
    "import pandas as pd         # Libreria per manipolare dati in formato tabellare (DataFrame)\n",
    "import matplotlib.pyplot as plt  # Libreria per creare grafici e visualizzazioni\n",
    "import seaborn as sns       # Libreria per visualizzazioni statistiche avanzate\n",
    "\n",
    "# --- Strumenti per la preparazione dei dati e validazione ---\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "# train_test_split: divide i dati in training e test set\n",
    "# KFold: divide i dati in k \"pieghe\" per la cross-validazione\n",
    "# cross_validate: esegue la validazione incrociata\n",
    "\n",
    "# --- Metriche di valutazione ---\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, make_scorer\n",
    "# mean_squared_error (MSE): errore quadratico medio\n",
    "# root_mean_squared_error (RMSE): radice dell'errore quadratico medio\n",
    "# mean_absolute_error (MAE): errore assoluto medio\n",
    "# make_scorer: crea metriche personalizzate\n",
    "\n",
    "# --- Tecniche di scaling/normalizzazione ---\n",
    "from sklearn.preprocessing import StandardScaler   # Standardizza i dati (media=0, deviazione standard=1)\n",
    "from sklearn.preprocessing import MinMaxScaler     # Normalizza i dati tra 0 e 1\n",
    "from sklearn.preprocessing import RobustScaler     # Scala i dati riducendo l'effetto degli outlier\n",
    "\n",
    "# --- Pipeline per concatenare trasformazioni ---\n",
    "from sklearn.pipeline import Pipeline  # Permette di creare flussi di lavoro concatenati\n",
    "\n",
    "# --- Modelli di Machine Learning ---\n",
    "from sklearn.dummy import DummyRegressor           # Modello baseline che fa predizioni semplici\n",
    "from sklearn.linear_model import LinearRegression  # Regressione lineare classica\n",
    "from sklearn.neighbors import KNeighborsRegressor  # Regressione basata sui k vicini più prossimi\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree  # Albero decisionale per regressione\n",
    "\n",
    "# --- Strumenti per ottimizzazione iperparametri ---\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# GridSearchCV: ricerca esaustiva dei migliori iperparametri\n",
    "# RandomizedSearchCV: ricerca casuale dei migliori iperparametri (più veloce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802b55e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d126b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ File caricato con successo: 992 righe, 37 colonne\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Id</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>mszoning_num</th>\n",
       "      <th>HasMiscFeature</th>\n",
       "      <th>HouseStyle_num</th>\n",
       "      <th>st_grvl_pave</th>\n",
       "      <th>ut_allpub_nosewa</th>\n",
       "      <th>land_slope_ord</th>\n",
       "      <th>roof_style_num</th>\n",
       "      <th>foundation_num</th>\n",
       "      <th>heating_num</th>\n",
       "      <th>electrical_num</th>\n",
       "      <th>central_air_num</th>\n",
       "      <th>garage_num</th>\n",
       "      <th>garage_finish_num</th>\n",
       "      <th>paveddrive_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labeled</td>\n",
       "      <td>1</td>\n",
       "      <td>6173</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>1967</td>\n",
       "      <td>876</td>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>labeled</td>\n",
       "      <td>2</td>\n",
       "      <td>11200</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1298</td>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "      <td>1298</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2</td>\n",
       "      <td>403</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>labeled</td>\n",
       "      <td>3</td>\n",
       "      <td>11924</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1175</td>\n",
       "      <td>1182</td>\n",
       "      <td>1142</td>\n",
       "      <td>2324</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>3</td>\n",
       "      <td>736</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labeled</td>\n",
       "      <td>4</td>\n",
       "      <td>6882</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>684</td>\n",
       "      <td>773</td>\n",
       "      <td>582</td>\n",
       "      <td>1355</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>labeled</td>\n",
       "      <td>5</td>\n",
       "      <td>4280</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>440</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90350.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Split  Id  LotArea  YearBuilt  YearRemodAdd  TotalBsmtSF  1stFlrSF  \\\n",
       "0  labeled   1     6173     1967.0          1967          876       902   \n",
       "1  labeled   2    11200     1985.0          1985         1298      1298   \n",
       "2  labeled   3    11924     2005.0          2006         1175      1182   \n",
       "3  labeled   4     6882     1914.0          2006          684       773   \n",
       "4  labeled   5     4280     1913.0          2002          440       694   \n",
       "\n",
       "   2ndFlrSF  GrLivArea  BsmtFullBath  FullBath  BedroomAbvGr  KitchenAbvGr  \\\n",
       "0         0        902             0         1             3             1   \n",
       "1         0       1298             1         2             3             1   \n",
       "2      1142       2324             1         3             4             1   \n",
       "3       582       1355             0         1             3             1   \n",
       "4         0        694             0         1             2             1   \n",
       "\n",
       "   TotRmsAbvGrd  Fireplaces  GarageYrBlt  GarageCars  GarageArea  OpenPorchSF  \\\n",
       "0             6           0       1967.0           1         288            0   \n",
       "1             5           1       1985.0           2         403           26   \n",
       "2            11           2       2005.0           3         736           21   \n",
       "3             7           0          0.0           0           0            0   \n",
       "4             4           1       1990.0           1         352            0   \n",
       "\n",
       "   EnclosedPorch  PoolArea  MiscFeature  SalePrice  mszoning_num  \\\n",
       "0              0         0            0   125500.0           3.0   \n",
       "1              0         0            0   180000.0           3.0   \n",
       "2              0         0            0   345000.0           3.0   \n",
       "3            115         0            0   127000.0           2.0   \n",
       "4             34         0            0    90350.0           3.0   \n",
       "\n",
       "   HasMiscFeature  HouseStyle_num  st_grvl_pave  ut_allpub_nosewa  \\\n",
       "0               0             1.0             1                 1   \n",
       "1               0             1.0             1                 1   \n",
       "2               0             5.0             1                 1   \n",
       "3               0             5.0             1                 1   \n",
       "4               0             1.0             1                 1   \n",
       "\n",
       "   land_slope_ord  roof_style_num  foundation_num  heating_num  \\\n",
       "0               0             2.0             2.0          3.0   \n",
       "1               0             2.0             2.0          3.0   \n",
       "2               0             3.0             3.0          3.0   \n",
       "3               0             2.0             3.0          3.0   \n",
       "4               0             2.0             3.0          3.0   \n",
       "\n",
       "   electrical_num  central_air_num  garage_num  garage_finish_num  \\\n",
       "0             3.0                1         3.0                  1   \n",
       "1             3.0                1         3.0                  1   \n",
       "2             3.0                1         4.0                  3   \n",
       "3             3.0                1         0.0                  0   \n",
       "4             3.0                0         2.0                  1   \n",
       "\n",
       "   paveddrive_num  \n",
       "0             1.0  \n",
       "1             1.0  \n",
       "2             1.0  \n",
       "3             1.0  \n",
       "4             0.5  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# SEZIONE: Caricamento dei Dati\n",
    "# ============================================\n",
    "# Carichiamo il dataset delle case dal file CSV\n",
    "# CSV = Comma Separated Values (file con valori separati da virgole)\n",
    "\n",
    "try:\n",
    "    # Proviamo a leggere il file CSV con i dati delle case\n",
    "    df = pd.read_csv('gb_house_pricing.csv')\n",
    "    \n",
    "    # Se il caricamento ha successo, mostriamo un messaggio di conferma\n",
    "    print(f\"✓ File caricato con successo: {len(df)} righe, {len(df.columns)} colonne\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    # Se il file non viene trovato, mostriamo un errore chiaro\n",
    "    print(\"❌ Errore: file 'gb_house_pricing.csv' non trovato!\")\n",
    "    print(\"   Assicurati che il file sia nella stessa cartella del notebook\")\n",
    "    raise  # Rilancia l'errore per fermare l'esecuzione\n",
    "    \n",
    "except Exception as e:\n",
    "    # Se ci sono altri errori durante il caricamento\n",
    "    print(f\"❌ Errore nel caricamento del file: {e}\")\n",
    "    raise  # Rilancia l'errore per fermare l'esecuzione\n",
    "\n",
    "# Impostiamo l'opzione per visualizzare tutte le colonne quando stampiamo il DataFrame\n",
    "# Normalmente pandas nasconde alcune colonne se sono troppe\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Mostriamo le prime 5 righe del dataset per avere un'idea dei dati\n",
    "# head() = \"testa\" in inglese, cioè mostra la parte iniziale dei dati\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b209eb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 37)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizziamo le dimensioni del dataset\n",
    "# shape restituisce una tupla (numero_righe, numero_colonne)\n",
    "# Questo ci aiuta a capire quanti dati abbiamo a disposizione\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a406de",
   "metadata": {},
   "source": [
    "Suddivisione fadi specific per questo caso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f9bb39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SEZIONE: Separazione dei Dati\n",
    "# ============================================\n",
    "# Il dataset contiene una colonna 'Split' che indica se i dati sono:\n",
    "# - 'labeled': dati con etichetta (SalePrice), usati per training/test\n",
    "# - 'leaderboard': dati senza etichetta, da usare per predizioni finali\n",
    "\n",
    "# Creiamo un DataFrame separato per i dati di training/test\n",
    "# .copy() crea una copia indipendente per evitare problemi di modifica\n",
    "train_df = df[df['Split'] == 'labeled'].copy()\n",
    "\n",
    "# Creiamo un DataFrame separato per i dati della leaderboard (predizioni finali)\n",
    "leaderboard_test_df = df[df['Split'] == 'leaderboard'].copy()\n",
    "\n",
    "# NOTA: la variabile 'last_pred' verrà creata più avanti nel notebook\n",
    "# quando faremo le predizioni finali sul set di leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51ae534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794, 37)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizziamo le dimensioni del set di training\n",
    "# Questo ci mostra quante case abbiamo per addestrare il modello\n",
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test \n",
    "\n",
    "\n",
    "ora he il momento di di isolare la colonna target e omettere colonna id e split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Separazione Features e Target\n",
    "# ============================================\n",
    "# Dividiamo i dati in:\n",
    "# - X: features (caratteristiche) - le informazioni che il modello usa per imparare\n",
    "# - y: target (obiettivo) - il valore che vogliamo predire (SalePrice = prezzo di vendita)\n",
    "\n",
    "# Creiamo X rimuovendo le colonne non utili per la predizione:\n",
    "# - 'Id': solo un identificatore\n",
    "# - 'Split': indica train/test, non è una caratteristica della casa\n",
    "# - 'SalePrice': è il target, non può essere una feature\n",
    "X = train_df.drop(['Id', 'Split', 'SalePrice'], axis=1)\n",
    "\n",
    "# Creiamo y prendendo solo la colonna del prezzo (quello che vogliamo predire)\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "# Dividiamo i dati in training set (80%) e test set (20%)\n",
    "# - Training set: usato per addestrare il modello\n",
    "# - Test set: usato per valutare le prestazioni su dati mai visti\n",
    "# random_state=42 garantisce che la divisione sia sempre la stessa\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni di X_train: (635, 34)\n",
      "Dimensioni di X_test : (159, 34)\n",
      "Dimensioni di y_train: (635,)\n",
      "Dimensioni di y_test : (159,)\n"
     ]
    }
   ],
   "source": [
    "# Visualizziamo le dimensioni dei set di training e test\n",
    "# Questo ci conferma che la divisione è avvenuta correttamente\n",
    "print(\"Dimensioni di X_train:\", X_train.shape)\n",
    "print(\"Dimensioni di X_test :\", X_test.shape)\n",
    "print(\"Dimensioni di y_train:\", y_train.shape)\n",
    "print(\"Dimensioni di y_test :\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Configurazione della Cross-Validation\n",
    "# ============================================\n",
    "# La cross-validation (validazione incrociata) divide i dati in K \"pieghe\" (folds)\n",
    "# e addestra il modello K volte, ogni volta usando una piega diversa per il test\n",
    "\n",
    "# KFold con 10 pieghe significa:\n",
    "# - Dividiamo i dati in 10 parti\n",
    "# - Usiamo 9 parti per addestrare e 1 per testare\n",
    "# - Ripetiamo 10 volte, cambiando ogni volta la parte usata per il test\n",
    "# shuffle=True: mescola i dati prima di dividerli\n",
    "# random_state=42: garantisce risultati riproducibili\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Definizione delle Metriche di Valutazione\n",
    "# ============================================\n",
    "# Definiamo le metriche per valutare quanto bene il nostro modello fa le predizioni:\n",
    "\n",
    "# 1. MSE (Mean Squared Error): errore quadratico medio\n",
    "#    - Più sensibile agli outlier (errori grandi pesano molto)\n",
    "#    - Risultato al quadrato, quindi difficile da interpretare\n",
    "# 2. RMSE (Root Mean Squared Error): radice dell'errore quadratico medio\n",
    "#    - Stesso scale del target (prezzo), più facile da interpretare\n",
    "# 3. MAE (Mean Absolute Error): errore assoluto medio\n",
    "#    - Meno sensibile agli outlier\n",
    "#    - Facile da interpretare: errore medio in dollari/euro\n",
    "\n",
    "# Nota: sklearn usa punteggi negativi (più alto = migliore)\n",
    "# quindi usiamo make_scorer con greater_is_better=False\n",
    "scoring = {\n",
    "    'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    'RMSE': make_scorer(root_mean_squared_error, greater_is_better=False),\n",
    "    'MAE': make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>test_RMSE</th>\n",
       "      <th>test_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.786764e+09</td>\n",
       "      <td>-42270.136243</td>\n",
       "      <td>-31752.942617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.292032e+09</td>\n",
       "      <td>-57376.232552</td>\n",
       "      <td>-45012.531141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.021331e+09</td>\n",
       "      <td>-54966.636330</td>\n",
       "      <td>-39328.887396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.347107e+09</td>\n",
       "      <td>-48446.949878</td>\n",
       "      <td>-40031.244637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>-3.300705e+09</td>\n",
       "      <td>-57451.762826</td>\n",
       "      <td>-42838.051007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>-2.780709e+09</td>\n",
       "      <td>-52732.431404</td>\n",
       "      <td>-38155.711871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-4.044157e+09</td>\n",
       "      <td>-63593.689870</td>\n",
       "      <td>-44686.888500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-3.120509e+09</td>\n",
       "      <td>-55861.512673</td>\n",
       "      <td>-40587.679515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>-2.599492e+09</td>\n",
       "      <td>-50985.216280</td>\n",
       "      <td>-40942.701576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>-1.681673e+09</td>\n",
       "      <td>-41008.210336</td>\n",
       "      <td>-31677.735043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time      test_MSE     test_RMSE      test_MAE\n",
       "0  0.000000    0.000000 -1.786764e+09 -42270.136243 -31752.942617\n",
       "1  0.000000    0.000000 -3.292032e+09 -57376.232552 -45012.531141\n",
       "2  0.000000    0.000000 -3.021331e+09 -54966.636330 -39328.887396\n",
       "3  0.008232    0.000000 -2.347107e+09 -48446.949878 -40031.244637\n",
       "4  0.000000    0.000994 -3.300705e+09 -57451.762826 -42838.051007\n",
       "5  0.000000    0.000999 -2.780709e+09 -52732.431404 -38155.711871\n",
       "6  0.001000    0.001000 -4.044157e+09 -63593.689870 -44686.888500\n",
       "7  0.001001    0.000998 -3.120509e+09 -55861.512673 -40587.679515\n",
       "8  0.000000    0.000999 -2.599492e+09 -50985.216280 -40942.701576\n",
       "9  0.001000    0.001002 -1.681673e+09 -41008.210336 -31677.735043"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# Modello Baseline (DummyRegressor)\n",
    "# ============================================\n",
    "# Prima di provare modelli complessi, creiamo un modello \"stupido\" (baseline)\n",
    "# che fa predizioni molto semplici. Questo ci dà un punto di riferimento:\n",
    "# se i nostri modelli complessi non battono il baseline, c'è qualcosa che non va!\n",
    "\n",
    "# DummyRegressor con strategy='mean' predice sempre la media del training set\n",
    "# È il modello più semplice possibile\n",
    "bl = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Eseguiamo la cross-validation per valutare il baseline\n",
    "# cv_results conterrà i punteggi per MSE, RMSE e MAE\n",
    "cv_results = cross_validate(bl, X_train, y_train, cv=kf, scoring=scoring)\n",
    "\n",
    "# Convertiamo i risultati in un DataFrame per visualizzarli meglio\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Mostriamo i risultati (i valori sono negativi, ma più alti = meglio)\n",
    "cv_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression \n",
    "\n",
    "e` buona cosa sempre iniziare con un rl cosi da vedere se e´o non e` questa tipologia di dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>test_RMSE</th>\n",
       "      <th>test_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>-2.785694e+08</td>\n",
       "      <td>-16690.399023</td>\n",
       "      <td>-12698.890167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>-4.201815e+08</td>\n",
       "      <td>-20498.329240</td>\n",
       "      <td>-14990.172162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>-3.857480e+08</td>\n",
       "      <td>-19640.467655</td>\n",
       "      <td>-13551.323635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>-2.182992e+08</td>\n",
       "      <td>-14774.950768</td>\n",
       "      <td>-11651.987493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>-3.269470e+08</td>\n",
       "      <td>-18081.674980</td>\n",
       "      <td>-13195.108167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>-3.856226e+08</td>\n",
       "      <td>-19637.276634</td>\n",
       "      <td>-14031.600067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>-5.994578e+08</td>\n",
       "      <td>-24483.827024</td>\n",
       "      <td>-17001.857712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>-3.769038e+08</td>\n",
       "      <td>-19414.010368</td>\n",
       "      <td>-13938.825895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>-1.551628e+08</td>\n",
       "      <td>-12456.435489</td>\n",
       "      <td>-9383.139220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>-2.641515e+08</td>\n",
       "      <td>-16252.738825</td>\n",
       "      <td>-13104.999965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time      test_MSE     test_RMSE      test_MAE\n",
       "0  0.005008    0.001993 -2.785694e+08 -16690.399023 -12698.890167\n",
       "1  0.004998    0.002002 -4.201815e+08 -20498.329240 -14990.172162\n",
       "2  0.004000    0.001999 -3.857480e+08 -19640.467655 -13551.323635\n",
       "3  0.005002    0.001999 -2.182992e+08 -14774.950768 -11651.987493\n",
       "4  0.004999    0.001999 -3.269470e+08 -18081.674980 -13195.108167\n",
       "5  0.005000    0.002000 -3.856226e+08 -19637.276634 -14031.600067\n",
       "6  0.005000    0.002000 -5.994578e+08 -24483.827024 -17001.857712\n",
       "7  0.003998    0.002002 -3.769038e+08 -19414.010368 -13938.825895\n",
       "8  0.004002    0.002002 -1.551628e+08 -12456.435489  -9383.139220\n",
       "9  0.003997    0.001997 -2.641515e+08 -16252.738825 -13104.999965"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# Regressione Lineare con Scaling\n",
    "# ============================================\n",
    "# La regressione lineare cerca di trovare la migliore linea (o iperpiano)\n",
    "# che passa attraverso i dati per fare predizioni\n",
    "\n",
    "# Usiamo una Pipeline che concatena due passaggi:\n",
    "# 1. StandardScaler: normalizza i dati (media=0, deviazione standard=1)\n",
    "#    - Importante perché le features hanno scale diverse\n",
    "# 2. LinearRegression: il modello di regressione lineare vero e proprio\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scale', StandardScaler()),     # Step 1: standardizza i dati\n",
    "    ('lr', LinearRegression())       # Step 2: applica regressione lineare\n",
    "])\n",
    "\n",
    "# Eseguiamo cross-validation sulla regressione lineare\n",
    "cv_results = cross_validate(lr, X_train, y_train, cv=kf, scoring=scoring)\n",
    "\n",
    "# Convertiamo i risultati in DataFrame\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Mostriamo i risultati\n",
    "cv_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Find good hyperparameters for the tree-based methods and kNN.\n",
    " • Use \n",
    " RandomizedSearchCV  and \n",
    " GridSearchCV  from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for the tree-based RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Iperparametro**          | **Tipo / Range consigliato per Randomized Search**                | **Descrizione**                                                                                                                                                                                                                                           |\n",
    "| -------------------------- | ----------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `criterion`                | `[\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"]`  | Funzione per misurare la qualità di una suddivisione. <br>• `squared_error`: minimizza MSE (default) <br>• `friedman_mse`: ottimizzato per boosting <br>• `absolute_error`: più robusto ai valori anomali <br>• `poisson`: per target positivi (conteggi) |\n",
    "| `splitter`                 | `[\"best\", \"random\"]`                                              | Strategia di divisione: <br>• `best` sceglie la miglior soglia <br>• `random` sceglie casualmente una soglia (utile per ridurre overfitting)                                                                                                              |\n",
    "| `max_depth`                | `Integer` (es. `randint(2, 50)`)                                  | Profondità massima dell’albero. Controlla la complessità. <br>• Più alto → rischio overfitting <br>• Più basso → rischio underfitting                                                                                                                     |\n",
    "| `min_samples_split`        | `Integer` o `Float` (es. `uniform(0.01, 0.3)` o `randint(2, 20)`) | Numero minimo di campioni richiesti per dividere un nodo. <br>Valori più alti rendono l’albero più semplice.                                                                                                                                              |\n",
    "| `min_samples_leaf`         | `Integer` o `Float` (es. `uniform(0.01, 0.2)` o `randint(1, 10)`) | Numero minimo di campioni richiesti in una foglia. <br>Riduce l’overfitting e impone foglie più grandi.                                                                                                                                                   |\n",
    "| `max_features`             | `[\"auto\", \"sqrt\", \"log2\", None]` o `uniform(0.3, 1.0)`            | Numero di feature considerate per trovare la miglior divisione. <br>• `None`: usa tutte le feature <br>• `sqrt`, `log2`: randomizza il sottoinsieme delle feature                                                                                         |\n",
    "| `max_leaf_nodes`           | `Integer` (es. `randint(10, 1000)` o `None`)                      | Numero massimo di foglie. <br>Limitandolo, si controlla la complessità del modello.                                                                                                                                                                       |\n",
    "| `min_impurity_decrease`    | `Float` (es. `uniform(0.0, 0.02)`)                                | Una divisione viene fatta solo se riduce l’impurità di almeno questo valore.                                                                                                                                                                              |\n",
    "| `ccp_alpha`                | `Float` (es. `uniform(0.0, 0.05)`)                                | Parametro di pruning (Cost Complexity Pruning). <br>Più alto → potatura più aggressiva → modello più semplice.                                                                                                                                            |\n",
    "| `random_state`             | `Integer` o `None`                                                | Fissa la casualità per rendere i risultati riproducibili.                                                                                                                                                                                                 |\n",
    "| `min_weight_fraction_leaf` | `Float` (es. `uniform(0.0, 0.5)`)                                 | Percentuale minima del peso totale dei campioni in una foglia. <br>Usato quando i dati hanno pesi.                                                                                                                                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parametri miogliori per dati che tendono a RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Iperparametro           | Scelta/Range consigliato                                    | Perché                                                            |\n",
    "| ----------------------- | ----------------------------------------------------------- | ----------------------------------------------------------------- |\n",
    "| `criterion`             | `[\"squared_error\", \"absolute_error\"]`                       | MSE per trend “puliti”; MAE se outlier.                           |\n",
    "| `splitter`              | `[\"best\"]` (eventuale `[\"best\",\"random\"]`)                  | Miglior soglia deterministica su singolo albero.                  |\n",
    "| `max_depth`             | `randint(2, 8)`                                             | Basso → forma quasi lineare (pochi scalini).                      |\n",
    "| `min_samples_split`     | `uniform(0.02, 0.28)` *(fraz.)* **oppure** `randint(2, 20)` | Più alto → meno partizioni. Preferisco frazione per scalabilità.  |\n",
    "| `min_samples_leaf`      | `uniform(0.02, 0.15)` *(frazione del dataset)*              | Foglie grandi → funzione più liscia.                              |\n",
    "| `max_features`          | `[None, 0.7, 0.85, 1.0, \"sqrt\"]`                            | Se poche feature utili, None/1.0; includo 0.7–0.85 per sicurezza. |\n",
    "| `max_leaf_nodes`        | `randint(6, 40)`                                            | Limita la complessità; con trend lineare bastano poche foglie.    |\n",
    "| `min_impurity_decrease` | `uniform(0.0, 0.002)`                                       | Evita split con guadagno trascurabile.                            |\n",
    "| `ccp_alpha`             | `uniform(0.0, 0.02)`                                        | Potatura cost-complexity leggera–media.                           |\n",
    "| `random_state`          | fisso (es. `42`)                                            | Riproducibilità.                                                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomizedSearchCV Parameters:\n",
      "\n",
      "   Hyperparameter   Best Value\n",
      "min_samples_split            5\n",
      " min_samples_leaf            2\n",
      "   max_leaf_nodes           32\n",
      "        max_depth            3\n",
      "        criterion friedman_mse\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SEZIONE: Ottimizzazione Iperparametri Decision Tree (RandomizedSearchCV)\n",
    "# ============================================\n",
    "# RandomizedSearchCV cerca i migliori iperparametri provando combinazioni casuali\n",
    "# È più veloce di GridSearchCV quando lo spazio di ricerca è grande\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Creiamo un Decision Tree base con parametri iniziali\n",
    "dt = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "\n",
    "# Definiamo i range di iperparametri da esplorare\n",
    "# Questi range sono ottimizzati per dati con trend tendenzialmente lineare\n",
    "param_dist = {\n",
    "    # Criterio per misurare la qualità di una divisione\n",
    "    \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\"],\n",
    "    \n",
    "    # Profondità massima dell'albero (None = nessun limite)\n",
    "    # Valori bassi = più regolarizzazione, meno overfitting\n",
    "    \"max_depth\": [3, 4, 5, 10, None],\n",
    "    \n",
    "    # Numero minimo di campioni richiesti per essere una foglia\n",
    "    # Valori più alti = più regolarizzazione\n",
    "    \"min_samples_leaf\": [0.02, 0.03, 0.05, 1, 2, 5],\n",
    "    \n",
    "    # Numero minimo di campioni richiesti per dividere un nodo\n",
    "    \"min_samples_split\": [0.05, 0.1, 0.15, 2, 5, 10, 20],\n",
    "    \n",
    "    # Numero massimo di foglie (None = nessun limite)\n",
    "    \"max_leaf_nodes\": [8, 12, 16, 24, 32, None],\n",
    "}\n",
    "\n",
    "# Creiamo il RandomizedSearchCV\n",
    "# IMPORTANTE: usiamo np.argmin perché vogliamo MINIMIZZARE il MAE\n",
    "# (i punteggi sono negativi in sklearn, quindi il valore più alto è il migliore,\n",
    "#  ma quando usiamo argmin cerchiamo direttamente il valore meno negativo = MAE più basso)\n",
    "dt_rscv = RandomizedSearchCV(\n",
    "    dt,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=scoring,              # Dizionario con metriche: {'MAE', 'MSE', 'RMSE'}\n",
    "    n_iter=1000,                  # Numero di combinazioni casuali da provare\n",
    "    return_train_score=True,      # Restituisce anche i punteggi sul training set\n",
    "    refit=lambda cvres: np.argmin(cvres['mean_test_MAE']),  # Seleziona il modello con MAE minimo\n",
    "    cv=kf,                        # Strategia di cross-validazione (KFold)\n",
    "    verbose=1,                    # Mostra progressi durante l'esecuzione\n",
    "    n_jobs=-1,                    # Usa tutti i core disponibili\n",
    "    random_state=42,              # Per risultati riproducibili\n",
    ")\n",
    "\n",
    "# Addestriamo il modello con tutti i parametri da provare\n",
    "dt_rscv.fit(X_train, y_train)\n",
    "\n",
    "# Otteniamo i migliori parametri trovati\n",
    "best_params = dt_rscv.best_params_\n",
    "\n",
    "# Creiamo una tabella con i migliori iperparametri\n",
    "best_params_table = pd.DataFrame(\n",
    "    list(best_params.items()), \n",
    "    columns=['Hyperparameter', 'Best Value']\n",
    ")\n",
    "\n",
    "# Mostriamo la tabella con i risultati\n",
    "print(\"Best RandomizedSearchCV Parameters:\\n\")\n",
    "print(best_params_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: -23644.219474441907\n",
      "Train MAE: -17843.829333078975\n",
      "Test RMSE: -27647.424390215754\n",
      "Test MAE: -20412.320375939853\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Risultati del Miglior Decision Tree\n",
    "# ============================================\n",
    "# Mostriamo le prestazioni del miglior modello trovato da RandomizedSearchCV\n",
    "\n",
    "# Otteniamo l'indice del miglior modello\n",
    "best_idx = dt_rscv.best_index_\n",
    "\n",
    "# Mostriamo i punteggi sul training set\n",
    "print('Train RMSE:', dt_rscv.cv_results_['mean_train_RMSE'][best_idx])\n",
    "print('Train MAE:', dt_rscv.cv_results_['mean_train_MAE'][best_idx])\n",
    "\n",
    "# Mostriamo i punteggi sul test set (cross-validation)\n",
    "print('Test RMSE:', dt_rscv.cv_results_['mean_test_RMSE'][best_idx])\n",
    "print('Test MAE:', dt_rscv.cv_results_['mean_test_MAE'][best_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for the tree-based GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for the kNN RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for the kNN GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for the GradientBoostingRegressor RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando... esto tardará unos 3-4 minutos\n",
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "\n",
      "✅ Entrenamiento completado!\n",
      "Mejores parámetros: {'gbr__criterion': 'friedman_mse', 'gbr__learning_rate': np.float64(0.038350904114546704), 'gbr__loss': 'squared_error', 'gbr__max_depth': 4, 'gbr__max_features': 'sqrt', 'gbr__min_impurity_decrease': np.float64(0.00027274295117353953), 'gbr__min_samples_leaf': np.float64(0.011309019910109373), 'gbr__min_samples_split': np.float64(0.08310576058518745), 'gbr__n_estimators': 247, 'gbr__subsample': np.float64(0.854657728648913)}\n",
      "Mejor MAE: 9793.698413275766\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. CREA EL PIPELINE\n",
    "pipe = Pipeline([\n",
    "    (\"gbr\", GradientBoostingRegressor(random_state=42)),\n",
    "])\n",
    "\n",
    "# 2. DEFINE KFOLD\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. DEFINE LOS PARÁMETROS (CON \"gbr__\" porque usas pipeline)\n",
    "param_dist = {\n",
    "    \"gbr__loss\": [\"squared_error\", \"huber\"],\n",
    "    \"gbr__learning_rate\": loguniform(0.001, 0.3),\n",
    "    \"gbr__n_estimators\": randint(150, 600),\n",
    "    \"gbr__subsample\": uniform(0.6, 0.4),\n",
    "    \"gbr__criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"gbr__min_samples_split\": uniform(0.02, 0.18),\n",
    "    \"gbr__min_samples_leaf\": uniform(0.01, 0.09),\n",
    "    \"gbr__max_depth\": randint(2, 5),\n",
    "    \"gbr__min_impurity_decrease\": uniform(0.0, 0.002),\n",
    "    \"gbr__max_features\": [None, 0.8, \"sqrt\"],\n",
    "}\n",
    "\n",
    "# 4. DEFINE SCORING\n",
    "scoring = {\n",
    "    \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"MAE\": \"neg_mean_absolute_error\",\n",
    "}\n",
    "\n",
    "# 5. RANDOMIZEDSEARCHCV\n",
    "gbr_rscv = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=scoring,\n",
    "    n_iter=80,\n",
    "    return_train_score=True,\n",
    "    refit='MAE',\n",
    "    cv=kf,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# 6. ENTRENA\n",
    "print(\"Entrenando... esto tardará unos 3-4 minutos\")\n",
    "gbr_rscv.fit(X_train, y_train)\n",
    "\n",
    "# 7. RESULTADOS\n",
    "print(\"\\n✅ Entrenamiento completado!\")\n",
    "print(\"Mejores parámetros:\", gbr_rscv.best_params_)\n",
    "print(\"Mejor MAE:\", -gbr_rscv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice SOTTO serve per identificare e mostrare i 5 modelli PEGGIORI NO migliori in base alla media di MAE (Mean Absolute Error) durante la ricerca randomizzata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 modelli con MAE più basso:\n",
      "\n",
      "Rank 1: MAE = 32613.844\n",
      "Parametri: {'gbr__criterion': 'squared_error', 'gbr__learning_rate': np.float64(0.001155571614655527), 'gbr__loss': 'squared_error', 'gbr__max_depth': 3, 'gbr__max_features': 'sqrt', 'gbr__min_impurity_decrease': np.float64(0.0008566289498802155), 'gbr__min_samples_leaf': np.float64(0.07196499106888297), 'gbr__min_samples_split': np.float64(0.030474847191519848), 'gbr__n_estimators': 271, 'gbr__subsample': np.float64(0.6625748170684344)}\n",
      "\n",
      "Rank 2: MAE = 32590.615\n",
      "Parametri: {'gbr__criterion': 'friedman_mse', 'gbr__learning_rate': np.float64(0.0010785962778329494), 'gbr__loss': 'squared_error', 'gbr__max_depth': 3, 'gbr__max_features': 0.8, 'gbr__min_impurity_decrease': np.float64(0.0007708330050798322), 'gbr__min_samples_leaf': np.float64(0.011436962699819277), 'gbr__min_samples_split': np.float64(0.061560888611986816), 'gbr__n_estimators': 241, 'gbr__subsample': np.float64(0.7760609974958406)}\n",
      "\n",
      "Rank 3: MAE = 32115.313\n",
      "Parametri: {'gbr__criterion': 'friedman_mse', 'gbr__learning_rate': np.float64(0.0016565580440884786), 'gbr__loss': 'squared_error', 'gbr__max_depth': 2, 'gbr__max_features': 0.8, 'gbr__min_impurity_decrease': np.float64(0.0006506606615265287), 'gbr__min_samples_leaf': np.float64(0.04498095607205338), 'gbr__min_samples_split': np.float64(0.06884282571930127), 'gbr__n_estimators': 202, 'gbr__subsample': np.float64(0.8347004662655393)}\n",
      "\n",
      "Rank 4: MAE = 31431.060\n",
      "Parametri: {'gbr__criterion': 'friedman_mse', 'gbr__learning_rate': np.float64(0.001315369545818121), 'gbr__loss': 'huber', 'gbr__max_depth': 2, 'gbr__max_features': 0.8, 'gbr__min_impurity_decrease': np.float64(0.0005217872466834279), 'gbr__min_samples_leaf': np.float64(0.011377408626134627), 'gbr__min_samples_split': np.float64(0.1880185354543069), 'gbr__n_estimators': 245, 'gbr__subsample': np.float64(0.9425959364753289)}\n",
      "\n",
      "Rank 5: MAE = 30464.882\n",
      "Parametri: {'gbr__criterion': 'friedman_mse', 'gbr__learning_rate': np.float64(0.0012504584990986303), 'gbr__loss': 'squared_error', 'gbr__max_depth': 2, 'gbr__max_features': None, 'gbr__min_impurity_decrease': np.float64(0.0005640691451426129), 'gbr__min_samples_leaf': np.float64(0.025969558940175053), 'gbr__min_samples_split': np.float64(0.15511065529535448), 'gbr__n_estimators': 341, 'gbr__subsample': np.float64(0.8303698301032338)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Visualizzazione dei 5 Migliori Modelli (Prima Versione)\n",
    "# ============================================\n",
    "# Questa cella mostra i 5 modelli con MAE più basso dalla prima ricerca\n",
    "\n",
    "# Ottieni gli indici dei 5 modelli con MAE più basso\n",
    "# argsort ordina i valori e restituisce gli indici\n",
    "# [:5] prende solo i primi 5\n",
    "best_indices = np.argsort(gbr_rscv.cv_results_['mean_test_MAE'])[:5]\n",
    "\n",
    "# Cicla attraverso i 5 migliori modelli e mostra i risultati\n",
    "print(\"Top 5 modelli con MAE più basso:\\n\")\n",
    "for rank, i in enumerate(best_indices, 1):\n",
    "    mae = abs(gbr_rscv.cv_results_['mean_test_MAE'][i])\n",
    "    print(f\"Rank {rank}: MAE = {mae:.3f}\")\n",
    "    print(\"Parametri:\", gbr_rscv.cv_results_['params'][i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "secondo round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ⚠️ Prerequisiti: gbr_rscv è già fit-tato; X_train, X_test, y_train, y_test sono definiti.\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1) Seleziona i 5 migliori in base a MAE (convertito in positivo)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m cv_mae_neg = \u001b[43mgbr_rscv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcv_results_\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmean_test_MAE\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m cv_rmse_neg = gbr_rscv.cv_results_.get(\u001b[33m'\u001b[39m\u001b[33mmean_test_RMSE\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     11\u001b[39m cv_mae = -cv_mae_neg\n",
      "\u001b[31mAttributeError\u001b[39m: 'RandomizedSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ⚠️ Prerequisiti: gbr_rscv è già fit-tato; X_train, X_test, y_train, y_test sono definiti.\n",
    "\n",
    "# 1) Seleziona i 5 migliori in base a MAE (convertito in positivo)\n",
    "cv_mae_neg = gbr_rscv.cv_results_['mean_test_MAE']\n",
    "cv_rmse_neg = gbr_rscv.cv_results_.get('mean_test_RMSE', None)\n",
    "cv_mae = -cv_mae_neg\n",
    "cv_rmse = -cv_rmse_neg if cv_rmse_neg is not None else None\n",
    "\n",
    "best_indices = np.argsort(cv_mae)[:5]\n",
    "\n",
    "# 2) Allena ciascun modello e valuta su train/test\n",
    "round2_rows = []\n",
    "for rank, i in enumerate(best_indices, start=1):\n",
    "    params = gbr_rscv.cv_results_['params'][i]\n",
    "    \n",
    "    # ✅ LIMPIA I PARAMETRI (rimuovi \"gbr__\")\n",
    "    clean_params = {k.replace('gbr__', ''): v for k, v in params.items() if k.startswith('gbr__')}\n",
    "\n",
    "    # Modello Round 2 con gli iperparametri puliti\n",
    "    model = GradientBoostingRegressor(random_state=42, **clean_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predizioni\n",
    "    y_pred_tr = model.predict(X_train)\n",
    "    y_pred_te = model.predict(X_test)\n",
    "\n",
    "    # Calcola MAE e RMSE per il training e la validation\n",
    "    mae_tr = mean_absolute_error(y_train, y_pred_tr)\n",
    "    mae_te = mean_absolute_error(y_test, y_pred_te)\n",
    "    rmse_tr = np.sqrt(mean_squared_error(y_train, y_pred_tr))\n",
    "    rmse_te = np.sqrt(mean_squared_error(y_test, y_pred_te))\n",
    "\n",
    "    row = {\n",
    "        \"Rank (by CV-MAE)\": rank,\n",
    "        \"CV MAE (mean)\": float(cv_mae[i]),\n",
    "        **({\"CV RMSE (mean)\": float(cv_rmse[i])} if cv_rmse is not None else {}),\n",
    "        \"Train MAE\": mae_tr,\n",
    "        \"Test MAE\": mae_te,\n",
    "        \"Train RMSE\": rmse_tr,\n",
    "        \"Test RMSE\": rmse_te,\n",
    "        \"Params\": clean_params  # ✅ Usa i parametri puliti\n",
    "    }\n",
    "    round2_rows.append(row)\n",
    "\n",
    "# 3) Tabella finale ordinata per Test MAE\n",
    "round2_df = pd.DataFrame(round2_rows)\n",
    "round2_df = round2_df.sort_values(by=\"Test MAE\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n🔁 Round 2 — Top-5 da CV per MAE (valutati su Train/Test):\\n\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(round2_df.to_string(index=False))\n",
    "\n",
    "# (Opzionale) Modello migliore su Test MAE\n",
    "best_round2_params = round2_df.iloc[0][\"Params\"]\n",
    "best_round2_model = GradientBoostingRegressor(random_state=42, **best_round2_params).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Se hai solo feature numeriche, puoi usare preprocessor=\"passthrough\"\n",
    "# Qui mostro un setup tipico con numeriche + categoriche\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_features),   # scaling leggero (GBR non richiede scaling, ma non fa danni)\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"gbr\", GradientBoostingRegressor(random_state=42)),\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"gbr__loss\": [\"squared_error\", \"huber\"],\n",
    "    \"gbr__learning_rate\": loguniform(1e-3, 3e-1),\n",
    "    \"gbr__n_estimators\": randint(150, 1201),\n",
    "    \"gbr__subsample\": uniform(0.6, 0.4),       # 0.6–1.0\n",
    "    \"gbr__max_depth\": randint(2, 5),           # 2–4\n",
    "    \"gbr__min_samples_split\": uniform(0.02, 0.18),\n",
    "    \"gbr__min_samples_leaf\": uniform(0.01, 0.09),\n",
    "    \"gbr__max_features\": [None, 1.0, 0.8, \"sqrt\"],\n",
    "    \"gbr__criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"gbr__min_impurity_decrease\": uniform(0.0, 0.002),\n",
    "    \"gbr__ccp_alpha\": uniform(0.0, 0.01),\n",
    "    # early-stopping interno del GBR\n",
    "    \"gbr__validation_fraction\": uniform(0.1, 0.1),  # 0.10–0.20\n",
    "    \"gbr__n_iter_no_change\": randint(5, 16),\n",
    "    \"gbr__tol\": loguniform(1e-5, 1e-3),\n",
    "}\n",
    "\n",
    "# Consiglio: usa scorer ufficiali negativi e lascia a sklearn scegliere il migliore con refit=\"RMSE\"\n",
    "scoring = {\n",
    "    \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"MAE\": \"neg_mean_absolute_error\",\n",
    "}\n",
    "\n",
    "gbr_rscv = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=80,            # compatto ma efficace\n",
    "    cv=kf,\n",
    "    scoring=scoring,\n",
    "    refit=\"RMSE\",         # migliore per RMSE (valori più \"alti\" perché negativi → migliore)\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "gbr_rscv.fit(X_train, y_train)\n",
    "print(\"Best params:\", gbr_rscv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Prestazioni del Miglior Modello\n",
    "# ============================================\n",
    "# Mostriamo le metriche del miglior modello GradientBoosting trovato\n",
    "\n",
    "print(\" Best GradientBoostingRegressor Performance:\\n\")\n",
    "\n",
    "# Mostriamo i punteggi sul training set (valori negativi convertiti in positivi)\n",
    "print(\"Train RMSE:\", (-gbr_rscv.cv_results_['mean_train_RMSE'][gbr_rscv.best_index_]))\n",
    "print(\"Train MAE:\", (-gbr_rscv.cv_results_['mean_train_MAE'][gbr_rscv.best_index_]))\n",
    "\n",
    "# Mostriamo i punteggi sul test set (cross-validation)\n",
    "print(\"Test RMSE:\", (-gbr_rscv.cv_results_['mean_test_RMSE'][gbr_rscv.best_index_]))\n",
    "print(\"Test MAE:\", (-gbr_rscv.cv_results_['mean_test_MAE'][gbr_rscv.best_index_]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dopo correzione prof "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora sono i 5 positivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Visualizzazione dei 5 Migliori Risultati\n",
    "# ============================================\n",
    "# Dopo aver eseguito RandomizedSearchCV, vogliamo vedere i 5 migliori modelli\n",
    "# trovati in base al Mean Absolute Error (MAE)\n",
    "\n",
    "# IMPORTANTE: I punteggi MAE in cv_results_ sono già NEGATIVI\n",
    "# Quindi per trovare i 5 MAE più bassi (migliori), cerchiamo i valori\n",
    "# MENO negativi (più vicini a zero), che sono i valori più ALTI\n",
    "# argsort ordina dal più piccolo al più grande, quindi prendiamo gli ultimi 5\n",
    "\n",
    "# Ottieni gli indici dei 5 migliori modelli (MAE più basso = valore meno negativo)\n",
    "# Non usiamo il segno meno perché i valori sono già negativi\n",
    "best_indices = np.argsort(gbr_rscv.cv_results_['mean_test_MAE'])[:5]\n",
    "\n",
    "# Mostra i 5 migliori risultati con MAE positivo (più facile da leggere)\n",
    "print(\"Top 5 migliori combinazioni per MAE:\\n\")\n",
    "for i in best_indices:\n",
    "    # Prendiamo il valore assoluto per mostrare MAE come numero positivo\n",
    "    mae = abs(gbr_rscv.cv_results_['mean_test_MAE'][i])\n",
    "    print(f\"Rank {i}: MAE = {mae:.3f}\")\n",
    "    print(\"Hyperparams:\", gbr_rscv.cv_results_['params'][i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "secondo round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ⚠️ Prerequisiti: gbr_rscv è già fit-tato; X_train, X_test, y_train, y_test, kf definiti.\n",
    "\n",
    "# 1) Prendi i 5 migliori in base a MAE di CV (positivo)\n",
    "cv_mae_neg = gbr_rscv.cv_results_['mean_test_MAE']              # negativo\n",
    "cv_rmse_neg = gbr_rscv.cv_results_.get('mean_test_RMSE', None)  # negativo (se presente)\n",
    "\n",
    "cv_mae = -cv_mae_neg\n",
    "cv_rmse = -cv_rmse_neg if cv_rmse_neg is not None else None\n",
    "\n",
    "best_indices = np.argsort(cv_mae)[:5]  # MAE più piccolo → migliore\n",
    "\n",
    "# 2) Refit dei 5 migliori e valutazione su Train/Test\n",
    "rows = []\n",
    "for rank, i in enumerate(best_indices, start=1):\n",
    "    params = gbr_rscv.cv_results_['params'][i]\n",
    "\n",
    "    model = GradientBoostingRegressor(random_state=42, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = model.predict(X_train)\n",
    "    y_pred_te = model.predict(X_test)\n",
    "\n",
    "    mae_tr = mean_absolute_error(y_train, y_pred_tr)\n",
    "    mae_te = mean_absolute_error(y_test,  y_pred_te)\n",
    "    rmse_tr = np.sqrt(mean_squared_error(y_train, y_pred_tr))\n",
    "    rmse_te = np.sqrt(mean_squared_error(y_test,  y_pred_te))\n",
    "\n",
    "    row = {\n",
    "        \"Rank by CV-MAE\": rank,\n",
    "        \"CV MAE (mean)\": float(cv_mae[i]),\n",
    "        **({\"CV RMSE (mean)\": float(cv_rmse[i])} if cv_rmse is not None else {}),\n",
    "        \"Train MAE\": mae_tr,\n",
    "        \"Test MAE\":  mae_te,\n",
    "        \"Train RMSE\": rmse_tr,\n",
    "        \"Test RMSE\":  rmse_te,\n",
    "        \"Params\": params\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# 3) Tabella finale ordinata per Test MAE (migliore in alto)\n",
    "df_round2 = pd.DataFrame(rows).sort_values(by=\"Test MAE\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n🔁 Round 2 — Top-5 (refit con stessi iperparametri, metriche positive):\\n\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df_round2.to_string(index=False))\n",
    "\n",
    "# (Opzionale) prendi il migliore del Round 2 e tienilo pronto\n",
    "best_params_r2 = df_round2.iloc[0][\"Params\"]\n",
    "best_model_r2 = GradientBoostingRegressor(random_state=42, **best_params_r2).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Se hai solo feature numeriche, puoi usare preprocessor=\"passthrough\"\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_features),  # ok con OHE (sparse)\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"gbr\", GradientBoostingRegressor(random_state=42)),\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"gbr__loss\": [\"squared_error\", \"huber\"],\n",
    "    \"gbr__learning_rate\": loguniform(1e-3, 3e-1),\n",
    "    \"gbr__n_estimators\": randint(150, 1201),\n",
    "    \"gbr__subsample\": uniform(0.6, 0.4),       # 0.6–1.0\n",
    "    \"gbr__max_depth\": randint(2, 5),           # 2–4\n",
    "    \"gbr__min_samples_split\": uniform(0.02, 0.18),\n",
    "    \"gbr__min_samples_leaf\": uniform(0.01, 0.09),\n",
    "    \"gbr__max_features\": [None, 1.0, 0.8, \"sqrt\"],\n",
    "    \"gbr__criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"gbr__min_impurity_decrease\": uniform(0.0, 0.002),\n",
    "    \"gbr__ccp_alpha\": uniform(0.0, 0.01),\n",
    "    # early-stopping interno del GBR\n",
    "    \"gbr__validation_fraction\": uniform(0.1, 0.1),  # 0.10–0.20\n",
    "    \"gbr__n_iter_no_change\": randint(5, 16),\n",
    "    \"gbr__tol\": loguniform(1e-5, 1e-3),\n",
    "}\n",
    "\n",
    "# Usiamo gli scorer \"neg_*\" standard, ma poi li mostriamo in positivo\n",
    "scoring = {\n",
    "    \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"MAE\": \"neg_mean_absolute_error\",\n",
    "}\n",
    "\n",
    "gbr_rscv = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=80,\n",
    "    cv=kf,                 # il tuo KFold\n",
    "    scoring=scoring,\n",
    "    refit=\"RMSE\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "gbr_rscv.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------------\n",
    "# Report in POSITIVO (senza cambiare la logica del search)\n",
    "# ------------------------------\n",
    "print(\"\\nBest params:\", gbr_rscv.best_params_)\n",
    "\n",
    "idx = gbr_rscv.best_index_\n",
    "train_rmse = abs(gbr_rscv.cv_results_['mean_train_RMSE'][idx])\n",
    "val_rmse   = abs(gbr_rscv.cv_results_['mean_test_RMSE'][idx])\n",
    "train_mae  = abs(gbr_rscv.cv_results_['mean_train_MAE'][idx])\n",
    "val_mae    = abs(gbr_rscv.cv_results_['mean_test_MAE'][idx])\n",
    "\n",
    "metrics_table = pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'MAE'],\n",
    "    'Train': [round(train_rmse, 4), round(train_mae, 4)],\n",
    "    'Validation': [round(val_rmse, 4), round(val_mae, 4)],\n",
    "})\n",
    "metrics_table['Difference'] = (metrics_table['Validation'] - metrics_table['Train']).round(4)\n",
    "metrics_table['% Diff'] = ((metrics_table['Difference'] / metrics_table['Train']) * 100).round(2)\n",
    "\n",
    "print(\"\\nModel Performance Summary (positive values):\\n\")\n",
    "print(metrics_table.to_string(index=False))\n",
    "\n",
    "# ------------------------------\n",
    "# (Opzionale) Top-5 per MAE (positivi) dalla CV\n",
    "# ------------------------------\n",
    "cv_mae_pos = -gbr_rscv.cv_results_['mean_test_MAE']\n",
    "top5_idx = np.argsort(cv_mae_pos)[:5]  # MAE più piccolo → migliore\n",
    "\n",
    "print(\"\\nTop-5 by CV MAE (positive):\\n\")\n",
    "for i in top5_idx:\n",
    "    mae = cv_mae_pos[i]\n",
    "    rmse = -gbr_rscv.cv_results_['mean_test_RMSE'][i]\n",
    "    print(f\"MAE={mae:.4f} | RMSE={rmse:.4f} | params={gbr_rscv.cv_results_['params'][i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Prestazioni del Modello (Valori Positivi)\n",
    "# ============================================\n",
    "# Visualizziamo le stesse metriche ma con valori positivi per maggiore chiarezza\n",
    "\n",
    "print(\"\\n--- Model Performance (positive values) ---\\n\")\n",
    "\n",
    "# Convertiamo i valori negativi in positivi per renderli più leggibili\n",
    "print('Train RMSE:', (-gbr_rscv.cv_results_['mean_train_RMSE'][gbr_rscv.best_index_]))\n",
    "print('Train MAE:', (-gbr_rscv.cv_results_['mean_train_MAE'][gbr_rscv.best_index_]))\n",
    "print('Test RMSE:', (-gbr_rscv.cv_results_['mean_test_RMSE'][gbr_rscv.best_index_]))\n",
    "print('Test MAE:', (-gbr_rscv.cv_results_['mean_test_MAE'][gbr_rscv.best_index_]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizziamo il DataFrame di leaderboard prima della pulizia\n",
    "# Questo mostra ancora tutte le colonne originali\n",
    "leaderboard_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Preparazione Dati per Predizione Finale\n",
    "# ============================================\n",
    "# Prima di fare le predizioni sul set di leaderboard, dobbiamo rimuovere\n",
    "# le colonne che non sono features (caratteristiche) utilizzabili dal modello\n",
    "\n",
    "# Rimuoviamo le colonne non necessarie:\n",
    "# - 'Split': indica solo se il dato era training o test\n",
    "# - 'Id': identificatore univoco, non utile per la predizione\n",
    "# - 'SalePrice': il target (che per il leaderboard non conosciamo)\n",
    "# \n",
    "# NOTA: quando usiamo 'columns=', non serve specificare 'axis=1'\n",
    "# perché è già implicito che stiamo eliminando colonne\n",
    "leaderboard_test_df = leaderboard_test_df.drop(columns=['Split', 'Id', 'SalePrice'])\n",
    "\n",
    "# Visualizziamo il DataFrame risultante\n",
    "leaderboard_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizziamo il miglior modello (estimator) trovato da RandomizedSearchCV\n",
    "# Questo mostra i parametri finali del modello migliore\n",
    "gbr_rscv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Predizione Finale sul Set di Leaderboard\n",
    "# ============================================\n",
    "# Ora che abbiamo trovato il miglior modello tramite RandomizedSearchCV,\n",
    "# lo usiamo per fare le predizioni sul set di leaderboard\n",
    "\n",
    "# Usiamo il miglior estimatore (modello) trovato da RandomizedSearchCV\n",
    "# best_estimator_ contiene il modello già addestrato con i migliori iperparametri\n",
    "# predict() fa le predizioni sulle nuove case (leaderboard_test_df)\n",
    "predizione = gbr_rscv.best_estimator_.predict(leaderboard_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizziamo l'array con tutte le predizioni\n",
    "# Questo ci mostra i prezzi predetti per ogni casa nel set di leaderboard\n",
    "predizione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Anteprima delle Prime Predizioni\n",
    "# ============================================\n",
    "# Visualizziamo le prime 10 predizioni per verificare che siano sensate\n",
    "\n",
    "# Mostriamo i primi 10 valori predetti\n",
    "# Questo ci aiuta a controllare che i prezzi siano realistici\n",
    "print(\"Prime 10 predizioni:\")\n",
    "print(predizione[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizziamo il DataFrame di leaderboard dopo la pulizia\n",
    "# Ora contiene solo le features utilizzabili per la predizione\n",
    "leaderboard_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Creazione del File di Submission\n",
    "# ============================================\n",
    "# Creiamo un DataFrame con gli ID e le predizioni per la submission finale\n",
    "\n",
    "# IMPORTANTE: range(795, 993) genera gli ID da 795 a 992\n",
    "# Questo range è specifico per questo dataset e NON deve essere modificato\n",
    "# Creiamo un DataFrame con:\n",
    "# - 'id': gli identificatori delle case (da 795 a 992)\n",
    "# - 'prediction': i prezzi predetti dal nostro modello\n",
    "last_pred = pd.DataFrame({\n",
    "    'id': range(795, 993), \n",
    "    'prediction': predizione\n",
    "})\n",
    "\n",
    "# Mostriamo le prime righe del DataFrame di submission\n",
    "last_pred.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Salvataggio del File di Submission\n",
    "# ============================================\n",
    "# Salviamo le predizioni in un file CSV per la submission finale\n",
    "\n",
    "# index=False: non salvare l'indice del DataFrame (solo id e prediction)\n",
    "# Questo crea il file 'submission.csv' nella cartella corrente\n",
    "last_pred.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"✓ File 'submission.csv' creato con successo!\")\n",
    "print(f\"  Contiene {len(last_pred)} predizioni\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
